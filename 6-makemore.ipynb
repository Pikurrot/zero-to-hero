{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makemore (Part 5)\n",
    "Building a WaveNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('/media/eric/D/datasets/names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle up the words\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... --> y\n",
      "..y --> u\n",
      ".yu --> h\n",
      "yuh --> e\n",
      "uhe --> n\n",
      "hen --> g\n",
      "eng --> .\n",
      "... --> d\n",
      "..d --> i\n",
      ".di --> o\n",
      "dio --> n\n",
      "ion --> d\n",
      "ond --> r\n",
      "ndr --> e\n",
      "dre --> .\n",
      "... --> x\n",
      "..x --> a\n",
      ".xa --> v\n",
      "xav --> i\n",
      "avi --> e\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(Xtr[:20], Ytr[:20]):\n",
    "  print(''.join(itos[ix.item()] for ix in x), '-->', itos[y.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Near copy paste of the layers we have developed in Part 3\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Linear:\n",
    "  \n",
    "  def __init__(self, fan_in, fan_out, bias=True):\n",
    "    self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5 # note: kaiming init\n",
    "    self.bias = torch.zeros(fan_out) if bias else None\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    self.out = x @ self.weight\n",
    "    if self.bias is not None:\n",
    "      self.out += self.bias\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class BatchNorm1d:\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.momentum = momentum\n",
    "    self.training = True\n",
    "    # parameters (trained with backprop)\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "    # buffers (trained with a running 'momentum update')\n",
    "    self.running_mean = torch.zeros(dim)\n",
    "    self.running_var = torch.ones(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    if self.training:\n",
    "      xmean = x.mean(0, keepdim=True) # batch mean\n",
    "      xvar = x.var(0, keepdim=True) # batch variance\n",
    "    else:\n",
    "      xmean = self.running_mean\n",
    "      xvar = self.running_var\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    # update the buffers\n",
    "    if self.training:\n",
    "      with torch.no_grad():\n",
    "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Tanh:\n",
    "  def __call__(self, x):\n",
    "    self.out = torch.tanh(x)\n",
    "    return self.out\n",
    "  def parameters(self):\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fab4c3f52b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22097\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "C = torch.randn((vocab_size, n_embd))\n",
    "layers = [\n",
    "  Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(n_hidden, vocab_size)\n",
    "]\n",
    "\n",
    "# parameter init\n",
    "with torch.no_grad():\n",
    "  layers[-1].weight *= 0.1 # last layer make less confident\n",
    "\n",
    "parameters = [C] + [p for layer in layers for p in layer.parameters()]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.2847\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters:\n\u001b[1;32m     21\u001b[0m   p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# update\u001b[39;00m\n\u001b[1;32m     25\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m150000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.01\u001b[39m \u001b[38;5;66;03m# step learning rate decay\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:164\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (tensors,)\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensors)\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\n\u001b[1;32m    165\u001b[0m     tensors: _TensorOrTensors,\n\u001b[1;32m    166\u001b[0m     grad_tensors: Optional[_TensorOrTensors] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    167\u001b[0m     retain_graph: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    168\u001b[0m     create_graph: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    169\u001b[0m     grad_variables: Optional[_TensorOrTensors] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    170\u001b[0m     inputs: Optional[_TensorOrTensorsOrGradEdge] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    171\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the sum of gradients of given tensors with respect to graph\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m    leaves.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m            were used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  emb = C[Xb] # embed the characters into vectors\n",
    "  x = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "  for layer in layers:\n",
    "    x = layer(x)\n",
    "  loss = F.cross_entropy(x, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for a nicer plot, we make stacks of 200 out of `lossi` and compute the mean on them (we remove noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f62ca2ef810>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The step decrease there is the learning rate decay, that alows us to optimize more to the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some improvements\n",
    "We create modules for the `C` matrix (`Embedding`) and the `emb.view(..., -1)` (`Flatten`). Also, we define `Sequentail`, a \"container\" that organizes the layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "  \n",
    "  def __init__(self, num_embeddings, embedding_dim):\n",
    "    self.weight = torch.randn((num_embeddings, embedding_dim))\n",
    "    \n",
    "  def __call__(self, IX):\n",
    "    self.out = self.weight[IX]\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight]\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Flatten:\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    self.out = x.view(x.shape[0], -1)\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Sequential:\n",
    "  \n",
    "  def __init__(self, layers):\n",
    "    self.layers = layers\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    # get parameters of all layers and stretch them out into one list\n",
    "    return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12097\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "# C = torch.randn((vocab_size, n_embd))\n",
    "model = Sequential([\n",
    "  Embedding(vocab_size, n_embd),\n",
    "  Flatten(),\n",
    "  Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(n_hidden, vocab_size)\n",
    "])\n",
    "\n",
    "# parameter init\n",
    "with torch.no_grad():\n",
    "  model.layers[-1].weight *= 0.1 # last layer make less confident\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3351\n",
      "  10000/ 200000: 2.5621\n",
      "  20000/ 200000: 2.3125\n",
      "  30000/ 200000: 2.4483\n",
      "  40000/ 200000: 2.1495\n",
      "  50000/ 200000: 1.8956\n",
      "  60000/ 200000: 2.3203\n",
      "  70000/ 200000: 2.0809\n",
      "  80000/ 200000: 2.1061\n",
      "  90000/ 200000: 2.5306\n",
      " 100000/ 200000: 2.0857\n",
      " 110000/ 200000: 2.5164\n",
      " 120000/ 200000: 2.3464\n",
      " 130000/ 200000: 2.4399\n",
      " 140000/ 200000: 2.0227\n",
      " 150000/ 200000: 2.2756\n",
      " 160000/ 200000: 2.3525\n",
      " 170000/ 200000: 1.9358\n",
      " 180000/ 200000: 1.8819\n",
      " 190000/ 200000: 1.8896\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  logits = model(Xb)\n",
    "  loss = F.cross_entropy(logits, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put layers into eval mode (needed for batchnorm especially)\n",
    "for layer in model.layers:\n",
    "  layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.059307098388672\n",
      "val 2.103390693664551\n"
     ]
    }
   ],
   "source": [
    "# evaluate the loss\n",
    "@torch.no_grad() # this decorator disables gradient tracking inside pytorch\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  logits = model(x)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vik.\n",
      "ris.\n",
      "emmulsella.\n",
      "zany.\n",
      "ino.\n",
      "edwearstofer.\n",
      "ali.\n",
      "hilopaly.\n",
      "kette.\n",
      "safrian.\n",
      "chad.\n",
      "taniy.\n",
      "kaelie.\n",
      "calayron.\n",
      "tim.\n",
      "javellieoliem.\n",
      "kai.\n",
      "demersyn.\n",
      "wan.\n",
      "calilann.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # forward pass the neural net\n",
    "      logits = model(torch.tensor([context]))\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      # sample from the distribution\n",
    "      ix = torch.multinomial(probs, num_samples=1).item()\n",
    "      # shift the context window and track the samples\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      # if we sample the special '.' token, break\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Wavenet\n",
    "Paper: https://arxiv.org/abs/1609.03499  \n",
    "First, we will take a context lenght of 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 8]) torch.Size([182625])\n",
      "torch.Size([22655, 8]) torch.Size([22655])\n",
      "torch.Size([22866, 8]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 8 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ --> y\n",
      ".......y --> u\n",
      "......yu --> h\n",
      ".....yuh --> e\n",
      "....yuhe --> n\n",
      "...yuhen --> g\n",
      "..yuheng --> .\n",
      "........ --> d\n",
      ".......d --> i\n",
      "......di --> o\n",
      ".....dio --> n\n",
      "....dion --> d\n",
      "...diond --> r\n",
      "..diondr --> e\n",
      ".diondre --> .\n",
      "........ --> x\n",
      ".......x --> a\n",
      "......xa --> v\n",
      ".....xav --> i\n",
      "....xavi --> e\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(Xtr[:20], Ytr[:20]):\n",
    "  print(''.join(itos[ix.item()] for ix in x), '-->', itos[y.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22097\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "# C = torch.randn((vocab_size, n_embd))\n",
    "model = Sequential([\n",
    "  Embedding(vocab_size, n_embd),\n",
    "  Flatten(),\n",
    "  Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(n_hidden, vocab_size)\n",
    "])\n",
    "\n",
    "# parameter init\n",
    "with torch.no_grad():\n",
    "  model.layers[-1].weight *= 0.1 # last layer make less confident\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Pytorch tip:  \n",
    "We can do `torch.rand(4, 5, 2, 80) @ torch.rand(80, 200) + torch.rand(200)` and that would work, just that `@` will be doing the matrix multiplication only on the last dimension (80 in the first tensor) and the rest will remain unchanged, they are treated as batch dimensions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this time, instead of flattening all the input characters into a single dimension, we will group them in pairs, and this will be treated as a \"batch dimension\": (1, 2, 3, 4, 5, 6, 7, 8) --> ((1, 2), (3, 4), (5, 6), (7, 8))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  8,  1, 26,  5, 14],\n",
       "        [ 0,  0,  0,  4, 15, 13,  9, 14],\n",
       "        [ 0,  0,  0,  0,  0, 14,  1, 20]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = torch.randint(0, Xtr.shape[0], (4,))\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "logits = model(Xb)\n",
    "print(Xb.shape)\n",
    "Xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 10])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].out.shape # output of Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 80])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].out.shape # output of Flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 200])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[2].out.shape # output of Linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modify the Embedding layer accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 200])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before:\n",
    "# (torch.rand(4, 80) @ torch.rand(80, 200) + torch.rand(200)).shape\n",
    "# Now, 4 groups of 2, each of one 10 dimensional vector (so 20):\n",
    "(torch.rand(4, 4, 20) @ torch.rand(20, 200) + torch.rand(200)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 20])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = torch.randn(4, 8, 10) # goal: we want this to be (4, 4, 20) where consecutive 10-d vectors get concatenated\n",
    "explicit = torch.cat([e[:, ::2, :], e[:, 1::2, :]], dim=2) # this works\n",
    "explicit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(e.view(4, 4, 20) == explicit).all() # but this also works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we define `FlattenConsecutive` class that works like `Flatten` but incorporating this change we made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenConsecutive:\n",
    "  \n",
    "  def __init__(self, n):\n",
    "    self.n = n\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    B, T, C = x.shape\n",
    "    x = x.view(B, T//self.n, C*self.n)\n",
    "    if x.shape[1] == 1:\n",
    "      x = x.squeeze(1)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22097\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "# C = torch.randn((vocab_size, n_embd))\n",
    "model = Sequential([\n",
    "  Embedding(vocab_size, n_embd),\n",
    "  FlattenConsecutive(block_size),\n",
    "  Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(n_hidden, vocab_size)\n",
    "])\n",
    "\n",
    "# parameter init\n",
    "with torch.no_grad():\n",
    "  model.layers[-1].weight *= 0.1 # last layer make less confident\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  1,  5, 13,  9, 15, 14],\n",
       "        [ 0,  0, 19,  5, 15, 10, 21, 14],\n",
       "        [ 0,  0,  0,  0,  0,  0,  2, 15],\n",
       "        [ 5, 13, 13,  1, 12,  5,  9,  7]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = torch.randint(0, Xtr.shape[0], (4,))\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "logits = model(Xb)\n",
    "print(Xb.shape)\n",
    "Xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding : (4, 8, 10)\n",
      "FlattenConsecutive : (4, 80)\n",
      "Linear : (4, 200)\n",
      "BatchNorm1d : (4, 200)\n",
      "Tanh : (4, 200)\n",
      "Linear : (4, 27)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "\tprint(layer.__class__.__name__, \":\", tuple(layer.out.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will restructure it to make it **hierarchically**, like in the Wavenet paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22397\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 68 # the number of neurons in the hidden layer of the MLP\n",
    "# we put 68 so that we have same number of parameters as before (to compare)\n",
    "\n",
    "# C = torch.randn((vocab_size, n_embd))\n",
    "model = Sequential([\n",
    "  Embedding(vocab_size, n_embd),\n",
    "  FlattenConsecutive(2), Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(n_hidden, vocab_size)\n",
    "])\n",
    "\n",
    "# parameter init\n",
    "with torch.no_grad():\n",
    "  model.layers[-1].weight *= 0.1 # last layer make less confident\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0, 13,  1,  3, 11, 25],\n",
       "        [ 0,  0,  0,  0, 10, 15,  4,  5],\n",
       "        [ 0,  0,  0,  0,  0,  8,  1, 14]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = torch.randint(0, Xtr.shape[0], (4,))\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "logits = model(Xb)\n",
    "print(Xb.shape)\n",
    "Xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding : (4, 8, 10)\n",
      "FlattenConsecutive : (4, 4, 20)\n",
      "Linear : (4, 4, 68)\n",
      "BatchNorm1d : (4, 4, 68)\n",
      "Tanh : (4, 4, 68)\n",
      "FlattenConsecutive : (4, 2, 136)\n",
      "Linear : (4, 2, 68)\n",
      "BatchNorm1d : (4, 2, 68)\n",
      "Tanh : (4, 2, 68)\n",
      "FlattenConsecutive : (4, 136)\n",
      "Linear : (4, 68)\n",
      "BatchNorm1d : (4, 68)\n",
      "Tanh : (4, 68)\n",
      "Linear : (4, 27)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "\tprint(layer.__class__.__name__, \":\", tuple(layer.out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 27])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we train this model (same n of parameters but hierarchical), the loss we get is almost the same. Because:\n",
    "1. We should to a hyperparameter search, as for now we just made a guess.\n",
    "2. There is a bug on BatchNorm1d(): it asumes the input is 2d, but it's 3d.\n",
    "\n",
    "Currently, we have this, where the mean and variance still keeps the same dimension 4. So it is working on parallel, 4 times over the 68 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4, 68])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = torch.randn(32, 4, 68)\n",
    "emean = e.mean(0, keepdim=True) # 1, 4, 68\n",
    "evar = e.var(0, keepdim=True) # 1, 4, 68\n",
    "ehat = (e - emean) / torch.sqrt(evar + 1e-5) # 32, 4, 68\n",
    "ehat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But for the mean and var we can pass a tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4, 68])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = torch.randn(32, 4, 68)\n",
    "emean = e.mean((0, 1), keepdim=True) # 1, 1, 68\n",
    "evar = e.var((0, 1), keepdim=True) # 1, 1, 68\n",
    "ehat = (e - emean) / torch.sqrt(evar + 1e-5) # 32, 4, 68\n",
    "ehat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shape remains the same, but we see how the mean and var have been applyed over both the dimensions 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 68]), torch.Size([1, 1, 68]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emean.shape, evar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm1d:\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.momentum = momentum\n",
    "    self.training = True\n",
    "    # parameters (trained with backprop)\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "    # buffers (trained with a running 'momentum update')\n",
    "    self.running_mean = torch.zeros(dim)\n",
    "    self.running_var = torch.ones(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    if self.training:\n",
    "      if x.ndim == 2:\n",
    "        dim = 0\n",
    "      elif x.ndim == 3:\n",
    "        dim = (0,1)\n",
    "      xmean = x.mean(dim, keepdim=True) # batch mean\n",
    "      xvar = x.var(dim, keepdim=True) # batch variance\n",
    "    else:\n",
    "      xmean = self.running_mean\n",
    "      xvar = self.running_var\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    # update the buffers\n",
    "    if self.training:\n",
    "      with torch.no_grad():\n",
    "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the network again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22397\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 68 # the number of neurons in the hidden layer of the MLP\n",
    "# we put 68 so that we have same number of parameters as before (to compare)\n",
    "\n",
    "# C = torch.randn((vocab_size, n_embd))\n",
    "model = Sequential([\n",
    "  Embedding(vocab_size, n_embd),\n",
    "  FlattenConsecutive(2), Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(n_hidden, vocab_size)\n",
    "])\n",
    "\n",
    "# parameter init\n",
    "with torch.no_grad():\n",
    "  model.layers[-1].weight *= 0.1 # last layer make less confident\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.2973\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  logits = model(Xb)\n",
    "  loss = F.cross_entropy(logits, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding : (32, 8, 10)\n",
      "FlattenConsecutive : (32, 4, 20)\n",
      "Linear : (32, 4, 68)\n",
      "BatchNorm1d : (32, 4, 68)\n",
      "Tanh : (32, 4, 68)\n",
      "FlattenConsecutive : (32, 2, 136)\n",
      "Linear : (32, 2, 68)\n",
      "BatchNorm1d : (32, 2, 68)\n",
      "Tanh : (32, 2, 68)\n",
      "FlattenConsecutive : (32, 136)\n",
      "Linear : (32, 68)\n",
      "BatchNorm1d : (32, 68)\n",
      "Tanh : (32, 68)\n",
      "Linear : (32, 27)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "\tprint(layer.__class__.__name__, \":\", tuple(layer.out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 68])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].running_mean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we'd run the full trainig, we would see that the loss improvement is negligible. This is because we need to increase the size of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76579\n"
     ]
    }
   ],
   "source": [
    "n_embd = 24 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 128 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "# C = torch.randn((vocab_size, n_embd))\n",
    "model = Sequential([\n",
    "  Embedding(vocab_size, n_embd),\n",
    "  FlattenConsecutive(2), Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(n_hidden, vocab_size)\n",
    "])\n",
    "\n",
    "# parameter init\n",
    "with torch.no_grad():\n",
    "  model.layers[-1].weight *= 0.1 # last layer make less confident\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  logits = model(Xb)\n",
    "  loss = F.cross_entropy(logits, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())\n",
    "  break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
