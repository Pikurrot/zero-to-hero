{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makemore (Part 4)\n",
    "Here we manually implement backpropagation for a multilayer perceptron, using tensors this time, with the aim of understanding it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('/media/eric/D/datasets/names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3460, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t# this is the ubiased estimate (1/n would be biased estimate)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape, counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**: backprop through the whole thing manually, backpropagating through exactly all of the variables as they are defined in the forward pass above, one by one:\n",
    "\n",
    "First, `dloss` is of course 1 (as changing `loss` always influences how `loss` changes by a factor of 1) so we skip it.  \n",
    "\n",
    "Next, we want to know `dloss/dlogprobs`, the derivative of `logprobs` with respect to `loss` (how a change in `logprobs` influences the `loss`). `logprobs` is of shape 32x27 (32 examples and 27 outputs). However, only one output (the correct one) of each example influences the loss, so these will have non-zero gradients, the rest will be 0.\n",
    "\n",
    "Now, `loss = -logprobs[range(n), Yb].mean()`, so it's like the mean of a 1D vector: `f=-(a + b + c)/3=-1/3a -1/3b -1/3c`. For example, `df/da = -1/3`. So, for our `dlogprobs` tensor, we have to set everything to 0.0 except those indexed that must be -1/n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "cmp('logprobs', dlogprobs, logprobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local derivative `dlogprobs/dprobs` is easy: `1/probs`. But as we want `dloss/dprobs`, we multiply by `dlogprobs` as by **chainrule**. Observe what's happening: if probs is close to 1, characters are predicted correctly, so 1/1 = 1 and the gradient passes through, but if incorrectly, 1/0.1 > 1. So intuitively this operation is boosting the gradients of the examples with low probability assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dprobs = (1 / probs) * dlogprobs\n",
    "cmp('probs', dprobs, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `dcounts_sum_inv`, careful because in `probs = counts * counts_sum_inv`, `counts` has shape 32x27 and `counts_sum_inv` has shape 32x1, so this is actually two operations: broadcasting and then element-wise multiplication.  \n",
    "So first we backpropagate through multiplication and do chainrule: `_dcounts_sum_inv = counts * dprobs`.  \n",
    "For broadcasting, we have that the values of one vector are being used multiple times. We know from micrograd that this implies that the gradients will be summed up, so: `dcounts_sum_inv = (counts * dprobs).sum(dim=1, keepdim=True)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dcounts_sum_inv = (counts * dprobs).sum(dim=1, keepdim=True)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_sum_inv.shape, dcounts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dcounts_sum = -1*counts_sum**-2 * dcounts_sum_inv\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`counts` is used twice, so we have to compute first its contribution to `probs`: `_dcounts = counts_sum_inv * dprobs`.  \n",
    "And then to `counts_sum = counts.sum(1, keepdims=True)`. `counts_sum` is just a sum of all elements in each row of `counts`, so the derivative of each element of `counts_sum` with respect to each element of the corresponding row in `counts` is 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dcounts = counts_sum_inv * dprobs # 32x27 = 32x1 * 32x27\n",
    "# dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dcounts += dcounts_sum # 32x27 += 32x27 * 32x1\n",
    "cmp('counts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# dnorm_logits = norm_logits.exp() * dcounts\n",
    "dnorm_logits = counts * dcounts # more efficient\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we print `dlogit_maxes`, we would see the gradients are almost 0.0. This is because the operation `norm_logits = logits - logit_maxes` is only for numerical stability and shouldn't affect the final result at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# dlogit_maxes = (-torch.ones_like(logits) * dnorm_logits).sum(dim=1, keepdim=True)\n",
    "dlogit_maxes = -dnorm_logits.sum(dim=1, keepdim=True) # more efficient\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_logits.shape, logits.shape, logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# dlogits = torch.ones_like(logits) * dnorm_logits\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogits += F.one_hot(logits.max(dim=1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "cmp('logits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dh = dlogits @ W2.T\n",
    "cmp('h', dh, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([64, 27]), torch.Size([32, 27]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape, W2.shape, dlogits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dW2 = h.T @ dlogits\n",
    "cmp('W2', dW2, W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([27]), torch.Size([32, 27]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2.shape, dlogits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# db2 = (torch.ones_like(logits) * dlogits).sum(dim=0, keepdim=True)\n",
    "db2 = dlogits.sum(dim=0, keepdim=True)\n",
    "cmp('b2', db2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hpreact         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "# dhpreact = (1 - torch.tanh(hpreact) ** 2) * dh\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "cmp('hpreact', dhpreact, hpreact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 10]), torch.Size([27, 10]), torch.Size([32, 3]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape, C.shape, Xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "bngain          | exact: False | approximate: True  | maxdiff: 2.3283064365386963e-09\n",
      "bnbias          | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "bnraw           | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
      "bnvar_inv       | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "bnvar           | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "bndiff2         | exact: False | approximate: True  | maxdiff: 2.9103830456733704e-11\n",
      "bndiff          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
      "bnmeani         | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
      "embcat          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "W1              | exact: False | approximate: True  | maxdiff: 6.51925802230835e-09\n",
      "b1              | exact: False | approximate: True  | maxdiff: 4.6566128730773926e-09\n",
      "emb             | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "C               | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n"
     ]
    }
   ],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "dprobs = (1 / probs) * dlogprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(dim=1, keepdim=True)\n",
    "dcounts_sum = -1*counts_sum**-2 * dcounts_sum_inv\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts += dcounts_sum \n",
    "dnorm_logits = counts * dcounts\n",
    "dlogit_maxes = -dnorm_logits.sum(dim=1, keepdim=True)\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogits += F.one_hot(logits.max(dim=1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(dim=0, keepdim=True)\n",
    "dhpreact = (1.0 - h ** 2) * dh\n",
    "dbngain = (bnraw * dhpreact).sum(dim=0, keepdim=True)\n",
    "dbnbias = dhpreact.sum(dim=0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(dim=0, keepdim=True)\n",
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "dbndiff2 = 1/(n-1) * dbnvar\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbndiff += 2*bndiff * dbndiff2\n",
    "dbnmeani = -dbndiff.sum(dim=0, keepdim=True)\n",
    "dhprebn = dbndiff.clone()\n",
    "dhprebn += 1/n*dbnmeani\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(dim=0, keepdim=True)\n",
    "demb = dembcat.view(emb.shape)\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "  for j in range(Xb.shape[1]):\n",
    "    ix = Xb[k,j]\n",
    "    dC[ix] += demb[k,j] # += in case of multiple occurences\n",
    "\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**: backprop through cross_entropy but all in one go to complete this challenge look at the mathematical expression of the loss, take the derivative, simplify the expression, and just write it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3460135459899902 diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 6.752088665962219e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "dlogits = F.softmax(logits, dim=1)\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits /= n\n",
    "\n",
    "cmp(\"logits\", dlogits, logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore `logits` and `dlogits`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0677, 0.1005, 0.0195, 0.0503, 0.0186, 0.0798, 0.0242, 0.0363, 0.0183,\n",
       "        0.0297, 0.0347, 0.0397, 0.0385, 0.0260, 0.0337, 0.0138, 0.0096, 0.0187,\n",
       "        0.0157, 0.0547, 0.0449, 0.0214, 0.0266, 0.0721, 0.0592, 0.0262, 0.0199],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0677,  0.1005,  0.0195,  0.0503,  0.0186,  0.0798,  0.0242,  0.0363,\n",
       "        -0.9817,  0.0297,  0.0347,  0.0397,  0.0385,  0.0260,  0.0337,  0.0138,\n",
       "         0.0096,  0.0187,  0.0157,  0.0547,  0.0449,  0.0214,  0.0266,  0.0721,\n",
       "         0.0592,  0.0262,  0.0199], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n # multiply by n for us to scale and interpret it better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see they are equal to the previous probability in forward pass, but the correct index is subtracted by 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7253e-09, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0db2849350>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32 examples x 27 characters. Black squares are the positions of the correct indices (where we subtracted 1). We can interpret this as the neural net, when trainig, will have a force pulling up the probabilities of the correct indices, and pulling down the rest. And the amount of pull up and down is equalized (the sum is 0, as seen above). If we have an index whose logit is too overconfidently wrong, it will be pulled down more than the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**: backprop through batchnorm but all in one go to complete this challenge look at the mathematical expression of the output of batchnorm, take the derivative w.r.t. its input, simplify the expression, and just write it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4**: putting it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897\n",
      "      0/ 100000: 3.3157\n",
      "  10000/ 100000: 2.4742\n",
      "  20000/ 100000: 2.4488\n",
      "  30000/ 100000: 2.3257\n",
      "  40000/ 100000: 2.2248\n",
      "  50000/ 100000: 2.2843\n",
      "  60000/ 100000: 2.5610\n",
      "  70000/ 100000: 2.3813\n",
      "  80000/ 100000: 2.2345\n",
      "  90000/ 100000: 2.2138\n"
     ]
    }
   ],
   "source": [
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 10 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 100000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "\t# kick off optimization\n",
    "\tfor i in range(max_steps):\n",
    "\n",
    "\t\t# minibatch construct\n",
    "\t\tix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "\t\tXb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "\t\t# forward pass\n",
    "\t\temb = C[Xb] # embed the characters into vectors\n",
    "\t\tembcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "\t\t# Linear layer\n",
    "\t\thprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "\t\t# BatchNorm layer\n",
    "\t\t# -------------------------------------------------------------\n",
    "\t\tbnmean = hprebn.mean(0, keepdim=True)\n",
    "\t\tbnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "\t\tbnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "\t\tbnraw = (hprebn - bnmean) * bnvar_inv\n",
    "\t\thpreact = bngain * bnraw + bnbias\n",
    "\t\t# -------------------------------------------------------------\n",
    "\t\t# Non-linearity\n",
    "\t\th = torch.tanh(hpreact) # hidden layer\n",
    "\t\tlogits = h @ W2 + b2 # output layer\n",
    "\t\tloss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "\t\t# backward pass\n",
    "\t\tfor p in parameters:\n",
    "\t\t\tp.grad = None\n",
    "\t\t# loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "\t\t# manual backprop! #swole_doge_meme\n",
    "\t\t# -----------------\n",
    "\t\tdlogits = F.softmax(logits, 1)\n",
    "\t\tdlogits[range(n), Yb] -= 1\n",
    "\t\tdlogits /= n\n",
    "\t\t# 2nd layer backprop\n",
    "\t\tdh = dlogits @ W2.T\n",
    "\t\tdW2 = h.T @ dlogits\n",
    "\t\tdb2 = dlogits.sum(0)\n",
    "\t\t# tanh\n",
    "\t\tdhpreact = (1.0 - h**2) * dh\n",
    "\t\t# batchnorm backprop\n",
    "\t\tdbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "\t\tdbnbias = dhpreact.sum(0, keepdim=True)\n",
    "\t\tdhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\t\t# 1st layer\n",
    "\t\tdembcat = dhprebn @ W1.T\n",
    "\t\tdW1 = embcat.T @ dhprebn\n",
    "\t\tdb1 = dhprebn.sum(0)\n",
    "\t\t# embedding\n",
    "\t\tdemb = dembcat.view(emb.shape)\n",
    "\t\tdC = torch.zeros_like(C)\n",
    "\t\tfor k in range(Xb.shape[0]):\n",
    "\t\t\tfor j in range(Xb.shape[1]):\n",
    "\t\t\t\tix = Xb[k,j]\n",
    "\t\t\t\tdC[ix] += demb[k,j]\n",
    "\t\tgrads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "\t\t# -----------------\n",
    "\n",
    "\t\t# update\n",
    "\t\tlr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "\t\tfor p, grad in zip(parameters, grads):\n",
    "\t\t\t#p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "\t\t\tp.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "\t\t# track stats\n",
    "\t\tif i % 10000 == 0: # print every once in a while\n",
    "\t\t\tprint(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "\t\tlossi.append(loss.log10().item())\n",
    "\n",
    "\t\t# if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "\t\t# \tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 10)        | exact: False | approximate: True  | maxdiff: 1.1175870895385742e-08\n",
      "(30, 200)       | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "(200,)          | exact: False | approximate: True  | maxdiff: 5.122274160385132e-09\n",
      "(200, 27)       | exact: False | approximate: True  | maxdiff: 2.2351741790771484e-08\n",
      "(27,)           | exact: False | approximate: True  | maxdiff: 9.313225746154785e-09\n",
      "(1, 200)        | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n",
      "(1, 200)        | exact: False | approximate: True  | maxdiff: 4.6566128730773926e-09\n"
     ]
    }
   ],
   "source": [
    "# useful for checking your gradients (freeze \"with torch.no_grad():\" and unfreeze \"loss.backward()\")\n",
    "# for p,g in zip(parameters, grads):\n",
    "# \tcmp(str(tuple(p.shape)), g, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training (we didn't do it while running)\n",
    "\n",
    "with torch.no_grad():\n",
    "  # pass the training set through\n",
    "  emb = C[Xtr]\n",
    "  embcat = emb.view(emb.shape[0], -1)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  # measure the mean/std over the entire training set\n",
    "  bnmean = hpreact.mean(0, keepdim=True)\n",
    "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.3031163215637207\n",
      "val 2.3007500171661377\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mora.\n",
      "kmyan.\n",
      "seel.\n",
      "ndhayah.\n",
      "rethrelendrami.\n",
      "aderedielii.\n",
      "shi.\n",
      "jelleigin.\n",
      "ananar.\n",
      "kayzioh.\n",
      "kalin.\n",
      "shubergiaghies.\n",
      "kin.\n",
      "reellionn.\n",
      "pulanu.\n",
      "zey.\n",
      "dariyah.\n",
      "fael.\n",
      "ylay.\n",
      "myannyan.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # ------------\n",
    "      # forward pass:\n",
    "      # Embedding\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)      \n",
    "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "      hpreact = embcat @ W1 + b1\n",
    "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "      logits = h @ W2 + b2 # (N, vocab_size)\n",
    "      # ------------\n",
    "      # Sample\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
